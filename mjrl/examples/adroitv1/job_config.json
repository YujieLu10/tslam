{
    "env": "adroit-v1",
    "algorithm": "PPO",
    "seed": 123,
    "sample_mode": "trajectories",
    "rl_num_traj": 10,
    "rl_num_iter": 50,
    "num_cpu": 2,
    "save_freq": 25,
    "eval_rollouts": null,
    "exp_notes": "Example config for training policy with PPO on the adroitv1 touch task",
    "policy_size": [
        32,
        32
    ],
    "init_log_std": -0.5,
    "vf_hidden_size": [
        128,
        128
    ],
    "vf_batch_size": 64,
    "vf_epochs": 2,
    "vf_learn_rate": 0.001,
    "rl_step_size": 0.1,
    "rl_gamma": 0.995,
    "rl_gae": 0.97,
    "alg_hyper_params": {
        "clip_coef": 0.2,
        "epochs": 10,
        "mb_size": 64,
        "learn_rate": 0.0005
    }
}